---
title: "Full.Analysis"
author: "Berj Dekramanjian"
date: "2023-12-11"
output: pdf_document
---


```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)

```

# Loaded Packages
- tidyverse
- car
- scales
- pwr
- lme4
```{r Package, include=FALSE, warning=FALSE}
library(tidyverse)
library(car)
library(scales)
library(broom)
library(pwr)
library(lme4)
library(MASS)
library(multcomp)
library(dplyr)
```

# Descriptive Analysis

## Ability of Survey to be Representative of Citizen Scientists
```{r Data Load, echo = FALSE}
data <- read.csv("loaddata.csv", header = TRUE)
survey_data <- read.csv("CleanSurveydData.csv", header = TRUE)
message_data <- read.csv("CleanMessageData.csv", header = TRUE)
reports_data <- read.csv("CleanReportsData.csv", header = TRUE)
user_data <- read.csv("CleanUserData.csv", header = TRUE)
survey_completed <- read.csv("sureycompdata.csv", header = TRUE)
received_msgs <- read.csv("recmsgdata.csv", header = TRUE)
report_msg_wide <- read.csv("reportmsgwide.csv", header = TRUE)
report_msg_long <- read.csv("reportmsglong.csv", header = TRUE)
```

```{r Representation, echo = TRUE}
# Values
population_size <- 265227  # Total population that downloaded the app
sample_size <- 217         # Sample size who completed the survey
confidence_level_constant <- 1.96  # Z-value for 95% confidence level

# Assuming maximum variability since we don't know the population characteristics (p=0.5 for maximum variability)
p <- 0.5

# Calculate the margin of error using the formula with finite population correction
margin_of_error <- (confidence_level_constant * sqrt((p * (1 - p)) / sample_size)) / 
  (1 + ((confidence_level_constant^2 * p * (1 - p)) / 
          (sample_size * population_size)))

# Convert to percentage
margin_of_error_percentage <- margin_of_error * 100

# Calculate response rate and completion rate
invitations_seen <- 450
attempts_made <- 237
response_rate <- (attempts_made / invitations_seen) * 100
completion_rate <- (sample_size / attempts_made) * 100

list(margin_of_error_percentage = margin_of_error_percentage, 
     response_rate = response_rate, 
     completion_rate = completion_rate)
rm(population_size,sample_size, confidence_level_constant, p,margin_of_error, margin_of_error_percentage, invitations_seen, attempts_made, response_rate, completion_rate)
```

While the response rate of **52.66%** among those who viewed the invitation is robust, the overall completion rate from the 
total population of those who downloaded the app  is **0.0818%**, which raises concerns about how well the survey results represent the population of citizen scientists. Keeping in mind that we have no idea who is still active or even has the app on their phone to receive the invite. The margin of error at **6.65%** is somewhat higher than the typically desired **5%**, suggesting that the survey findings should be interpreted with caution. Due to the lack of visibility into active users versus those who have uninstalled the app, the survey results may not accurately reflect the current user base. As such, the survey findings are most representative of the subset of users who are engaged with the app to the extent that they have seen and responded to the in-app invite. The results, therefore, should be generalized to the broader population of all those who downloaded the app only with substantial caveats.


## Demographic variables

```{r demographic, echo = FALSE,}
# Descriptive statistics for demographic variables

summary(survey_completed %>% dplyr::select(Age, Age_Group, Gender, Country, Network, Other_Citi_Sci, Participation_Date))

```
Mean age of participants is **48.6**, and in line with findings from previous studies.
There is higher rate of male participation with **122** to **89**,where earlier findings had higher female or mostly equal participation rates.
Majority of reports were as expected from **3** countries: Spain, Italy, and Netherlands with **103,77**,and **22** participants respectively.
The vast majority have no acquaintances also participating, and are not part of other citizen science projects
The majority of participants are also as expected recent recruits from 2023 (**72**), and the participation drops as the the years go back (**54,40,21,10.....**)

### Age Distribution
```{r age, echo = FALSE, warning=FALSE}
ggplot(survey_completed, aes(x = Age)) +
  geom_histogram(binwidth = 5, fill = "#16697a", color = "#8491a3") +
  geom_vline(aes(xintercept = mean(Age, na.rm = TRUE)), color = "#d34e24", linetype = "dashed", size = 1) +
  labs(
    title = "Distribution of Ages",
    x = "Age (years)",
    y = "Count"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    plot.title = element_text(size = 16, face = "bold"),
    legend.position = "none"
  ) +
  annotate(
    "text",
    x = mean(survey_completed$Age, na.rm = TRUE),
    y = max(table(survey_completed$Age)),
    label = sprintf("Mean Age: %.1f", mean(survey_completed$Age, na.rm = TRUE)),
    vjust = -20,
    hjust = 1.1,
    size = 4,
    color = "#2d1e2f"
  ) 
```

### Gender Distribution

```{r gender, echo = FALSE, warning=FALSE}
ggplot(survey_completed, aes(x = reorder(Gender, -table(survey_completed$Gender)[Gender]))) +
  geom_bar(aes(fill = Gender), color = "#8491a3") +
  geom_text(stat='count', aes(label=..count..), vjust=-0.5, position=position_stack(vjust=0.5)) +
  labs(title = "Distribution of Gender", x = "Gender", y = "Citizen Scientists") +
  scale_fill_manual(values = c("#16697a","#e0c40d", "#d34e24",  "#38726c", "#c1dff0", "#8491a3", "#16302b")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none")
```

## Regulatory Focus & Motivators

```{r Reg and Mot, echo = FALSE,}
summary(survey_completed %>% dplyr::select(Reg_Orientation, Reg_Orientation_Cat, Openness_To_Change, Self_Enhancement, 
                                    Continuity, Self_Transcendence, Security, Teaching))
```

The average Regulatory orientation of survey takers is **-1.381**, meaning more prevention oriented as hypothesized, counter to the notion that a general population should be split equally and in western countries be more inclined to be promotion oriented. Checking the participants by categorization shows that by far the majority of users are of prevention-orientation with **121** to **70**.

Regarding the motivators, the two highest means were for Self Transcendence **4.23** and Security **4.23** with security having a higher median **5** followed by Openness to Change **3.24**, Teaching **2.26**, and very low scores for Continuity **1.8** and Self Enhancement **1.49**
  
###  Disrtibution 
  
```{r Reg Focus Disrtibution, echo = FALSE, warning=FALSE}
survey_completed %>%
  filter(!is.na(Reg_Orientation_Cat)) %>%
  ggplot(aes(x = fct_infreq(Reg_Orientation_Cat))) +
  geom_bar(aes(fill = Reg_Orientation_Cat), color = "#8491a3") +
  geom_text(stat = "count", aes(label = ..count..), vjust = -0.5, position = position_stack(vjust = 0.5)) +
  labs(title = "Distribution of Regulatory Orientation ",x = "Regulatory Orientation Category", y = "Citizen Scientists") +
  scale_fill_manual(values = c("#e0c40d", "#d34e24",  "#38726c", "#c1dff0", "#8491a3", "#16302b", "#16697a")) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none")
```

### Distribution of Regulatory Orientation Catagories By Gender

```{r Reg Focus GenderDisrtibution, echo = FALSE, warning=FALSE}
survey_completed %>%
  filter(!is.na(Reg_Orientation_Cat), !is.na(Gender),Gender %in% c("Male", "Female")) %>%
  group_by(Gender) %>%
  mutate(total_gender = n()) %>%
  group_by(Gender, Reg_Orientation_Cat, total_gender) %>%
  summarise(count = n(), .groups = 'drop_last') %>%
  ungroup() %>%
  mutate(percentage = (count / total_gender) * 100) %>%
  ggplot(aes(x = fct_infreq(Gender))) +
  geom_bar(aes(y = percentage, fill = Reg_Orientation_Cat), stat = "identity", position = "dodge", color = "#8491a3") +
  geom_text(aes(y = percentage, label = percent(percentage/100, accuracy = 1), group = Reg_Orientation_Cat),
            vjust = -0.5, position = position_dodge(width = 0.9), size = 2) +
  labs(title = "Distribution of Regulatory Orientation by Gender",
       x = "Gender", 
       y = "Percentage") +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  scale_fill_manual(values = c("#e0c40d", "#d34e24",  "#38726c", "#c1dff0", "#8491a3", "#16302b", "#16697a")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(fill = NULL)
```
The distribution seems mostly equal between genders

### Distribution of Regulatory Orientation Catagories By Age Group

```{r Reg Focus Age Disrtibution, echo = FALSE, warning=FALSE}
survey_completed %>%
  filter(!is.na(Reg_Orientation_Cat), !is.na(Age_Group)) %>%
  group_by(Age_Group) %>%
  mutate(total_age_group = n()) %>%
  group_by(Age_Group, Reg_Orientation_Cat, total_age_group) %>%
  summarise(count = n(), .groups = 'drop_last') %>%
  ungroup() %>%
  mutate(percentage = (count / total_age_group) * 100) %>%
  ggplot(aes(x = fct_infreq(Age_Group))) +
  geom_bar(aes(y = percentage, fill = Reg_Orientation_Cat), stat = "identity", position = "dodge", color = "#8491a3") +
  geom_text(aes(y = percentage, label = percent(percentage/100, accuracy = 1), group = Reg_Orientation_Cat),
            vjust = -0.5, position = position_dodge(width = 0.9), size = 2) +
  labs(title = "Distribution of Regulatory Orientation by Age Group ",
       x = "Age Group", 
       y = "Percentage") +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  scale_fill_manual(values = c("#e0c40d", "#d34e24",  "#38726c", "#c1dff0", "#8491a3", "#16302b", "#16697a")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(fill = NULL)
```
Distribution seems in general similar to the general distribution with prevention being a third higher than promotion orientation. The thing that stand out seem to be lack of **8-25** age group in neutral and higher representation in prevention, and a higher percentage of promotion orientation than usual for  **36-48** year segment.
  
  
### Distribution of Regulatory Orientation Catagories By Year of Initial Participation  
```{r Reg Focus participation year Disrtibution, echo = FALSE}
survey_completed %>%
  filter(!is.na(Reg_Orientation_Cat), !is.na(Participation_Date)) %>%
  filter(Participation_Date %in% c('2023', '2022', '2021', '2020', '2019')) %>%
  group_by(Participation_Date, Reg_Orientation_Cat) %>%
  summarise(Count = n(), .groups = 'drop_last') %>%
  group_by(Participation_Date) %>%
  mutate(Total = sum(Count), Percentage = Count / Total * 100) %>%
  ungroup() %>%
  ggplot(aes(x = factor(Participation_Date, levels = c("2023", "2022", "2021", "2020", "2019")), 
             y = Percentage, fill = Reg_Orientation_Cat)) +
  geom_bar(stat = "identity", position = "dodge", color = "#8491a3") +
  geom_text(aes(label = Count, y = Percentage + 2), 
            position = position_dodge(width = 0.9), size = 2) +
  labs(title = "Distribution of Regulatory Orientation by Participation Year",
       x = "Participation Year",
       y = "Percentage") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_manual(values = c("#e0c40d", "#d34e24",  "#38726c", "#c1dff0", "#8491a3", "#16302b", "#16697a")) +
  scale_y_continuous(limits = c(0, 75))+
  labs(fill = NULL)
```

It seems regardless of the major campaign this year the project seems to attract a higher percentage  prevention orientation individuals in general. The only year where we attract equal percentages is 2021, this might be due to the country of sign-ups, which should be clearer whith visualizing the distribution by country.

### Distribution of Regulatory Orientation Categories By Country

```{r Reg Focus participation Country Disrtibution, echo = FALSE}
survey_completed %>%
  filter(!is.na(Reg_Orientation_Cat), !is.na(Country)) %>% 
  group_by(Country, Reg_Orientation_Cat) %>%
  summarise(Count = n(), .groups = 'drop_last') %>%
  left_join(
    survey_completed %>%
      group_by(Country) %>%
      summarise(Total = n(), .groups = 'drop_last'), 
    by = "Country"
  ) %>%
  filter(Country %in% c("Spain", "Italy", "Netherlands", "Hungary")) %>%
  ggplot(aes(x = factor(Country, levels = c("Spain", "Italy", "Netherlands", "Hungary")), 
             y = Count, 
             fill = Reg_Orientation_Cat)) +
  geom_bar(stat = "identity", position = "dodge", color = "#8491a3") +
  geom_text(aes(label = Count), 
            position = position_dodge(width = 0.9), vjust = -0.5, size = 2) +
  labs(title = "Distribution of Regulatory Orientation by Country",
       y = "Count",
       x = "Country") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_manual(values = c("#e0c40d", "#d34e24",  "#38726c", "#c1dff0", "#8491a3", "#16302b", "#16697a")) +
  labs(fill = NULL)
```
As expected the Netherlands has the biggest discrepancy of promotion oriented individuals participating. And Spain is by far the place with the highest proportion of individuals with a prevention orientation.

## Motivation Disrtibution 

```{r Motivation Disrtibution, echo = FALSE, warning=FALSE}
survey_completed %>%
  summarise(
    Openness_To_Change = mean(Openness_To_Change, na.rm = TRUE),
    Self_Enhancement = mean(Self_Enhancement, na.rm = TRUE),
    Continuity = mean(Continuity, na.rm = TRUE),
    Self_Transcendence = mean(Self_Transcendence, na.rm = TRUE),
    Security = mean(Security, na.rm = TRUE),
    Teaching = mean(Teaching, na.rm = TRUE)
  ) %>%
  pivot_longer(cols = everything(), 
               names_to = "Motivator", 
               values_to = "Average") %>%
  ggplot(aes(x = gsub("_", " ", Motivator), y = Average, fill = Motivator)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = sprintf("%.2f", Average)), vjust = -0.5, size = 4, position = position_dodge(width = 0.7)) +
  labs(title = "Distribution of Average Motivator Ratings",
       y = "Citizen Scientist Rating over 5",
       x = "Motivator") +
  scale_fill_manual(values = c("#e0c40d", "#d34e24",  "#38726c", "#c1dff0", "#8491a3", "#16302b", "#16697a")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) +
  ylim(0, 5) +
  theme(axis.title.x = element_blank(),
        legend.position = "none") 

survey_completed %>%
  dplyr::select(Openness_To_Change:Teaching) %>%
  pivot_longer(cols = everything(), names_to = "Motivator", values_to = "Score") %>%
  ggplot(aes(x = gsub("_", " ", Motivator), y = Score, fill = Motivator)) +
  geom_boxplot() +
  labs(title = "Distribution Through Candle Stick Chart",
       x = "Motivator", y = "Score") +
  scale_fill_manual(values = c("#e0c40d", "#d34e24",  "#38726c", "#c1dff0", "#8491a3", "#16697a")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        legend.position = "none")
```

### Distribution of Average Motivator Ratings By Gender
```{r Motivation by Gender Disrtibution, echo = FALSE}
survey_completed %>%
  group_by(Gender) %>%
  summarise(
    Openness_To_Change = mean(Openness_To_Change, na.rm = TRUE),
    Self_Enhancement = mean(Self_Enhancement, na.rm = TRUE),
    Continuity = mean(Continuity, na.rm = TRUE),
    Self_Transcendence = mean(Self_Transcendence, na.rm = TRUE),
    Security = mean(Security, na.rm = TRUE),
    Teaching = mean(Teaching, na.rm = TRUE)
  ) %>%
  filter(Gender %in% c("Male", "Female")) %>% 
  pivot_longer(cols = -Gender, 
               names_to = "Motivator", 
               values_to = "Average") %>%
  ggplot(aes(x = fct_infreq(Gender))) +
  geom_bar(aes(y = Average, fill = Motivator), stat = "identity", position = "dodge", width = 0.7) +
  geom_text(aes(y = Average, label = sprintf("%.2f", Average), group = Motivator),
            position = position_dodge(width = 0.7), 
            vjust = -0.5, size = 3) +
  labs(title = "Motviation Distribution by Gender",
       y = "Average Rating",
       x = "Gender") +
  scale_fill_manual(values = c("#e0c40d", "#d34e24",  "#38726c", "#c1dff0", "#8491a3", "#16302b", "#16697a")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        legend.title = element_blank(),
        legend.position = "none") +
  ylim(0, 5) 
```
Both genders seem mostly similar in their rating of various motivators

### Distribution of Average Motivator Ratings By Age
```{r Motivation by Age Disrtibution, echo = FALSE}
survey_completed %>%
  group_by(Age_Group) %>%
  summarise(
    Openness_To_Change = mean(Openness_To_Change, na.rm = TRUE),
    Self_Enhancement = mean(Self_Enhancement, na.rm = TRUE),
    Continuity = mean(Continuity, na.rm = TRUE),
    Self_Transcendence = mean(Self_Transcendence, na.rm = TRUE),
    Security = mean(Security, na.rm = TRUE),
    Teaching = mean(Teaching, na.rm = TRUE)
  ) %>%
  pivot_longer(cols = -Age_Group, 
               names_to = "Motivator", 
               values_to = "Average") %>%
  ggplot(aes(x = fct_infreq(Age_Group), y = Average, fill = Motivator)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7, color = "#8491a3") +
  geom_text(aes(label = sprintf("%.2f", Average), group = Motivator),
            position = position_dodge(width = 0.7), 
            vjust = -0.5, size = 2) +
  labs(y = "Average Rating",
       x = "Age Group") +
  scale_fill_manual(values = c("#e0c40d", "#d34e24",  "#38726c", "#c1dff0", "#8491a3", "#16302b", "#16697a")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        legend.title = element_blank(),
        legend.position = "top") +
  ylim(0, 5)
```
Age groups mostly agree as well and are similar in their judgment of various motivators


### Distribution of Average Motivator Rating By Regulatory Focus

```{r Motivation by Regulatory Focus, echo = FALSE}

ggplot(
  survey_completed %>%
    filter(Reg_Orientation_Cat != "NA") %>%
    group_by(Reg_Orientation_Cat) %>%
    summarise(
      Openness_To_Change = mean(Openness_To_Change, na.rm = TRUE),
      Self_Enhancement = mean(Self_Enhancement, na.rm = TRUE),
      Continuity = mean(Continuity, na.rm = TRUE),
      Self_Transcendence = mean(Self_Transcendence, na.rm = TRUE),
      Security = mean(Security, na.rm = TRUE),
      Teaching = mean(Teaching, na.rm = TRUE) 
    ) %>%
    tidyr::pivot_longer(cols = -Reg_Orientation_Cat, 
                        names_to = "Motivator", 
                        values_to = "Average"),
  aes(x = Reg_Orientation_Cat, y = Average, fill = Motivator)
) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7) +
  geom_text(aes(label = sprintf("%.2f", Average), group=Motivator),
            position = position_dodge(width = 0.7), 
            vjust = -0.5, size = 3) +
  labs(y = "Average Rating",
       x = "Regulatory Orientation Category") +
  scale_fill_manual(values = c("#e0c40d", "#d34e24",  "#38726c", "#c1dff0", "#8491a3", "#16302b", "#16697a")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        legend.title = element_blank(),
        legend.position = "top") +
  ylim(0, 5)

```
Unlike what was expected, participants with differing regulatory orientations seem to rate motivators similarly in a survey setting, where the difference in security rating which was expected to be higher for prevention oriented users is mild.

```{r Motivation by Regulatory Focus Regression, echo = TRUE}
motivators <- c("Openness_To_Change", "Self_Enhancement", "Continuity", 
                "Self_Transcendence", "Security", "Teaching")

sapply(motivators, function(motivator) {
  p_value <- summary(lm(data = survey_completed, formula = as.formula(paste(motivator, "~ Reg_Orientation"))))$coefficients[2, 4]
  cat("Motivator:", motivator, "\tP-value:", p_value, "\n")
  p_value
})
rm(motivators)
```

Completing a quick regression analysis shows no significant relationships, where the p value for each motivator was much higher than 0.05





## Messages Distribution

For the summer message experiment out of **265,227** registered citizen scientists **237** got messages, of which **217** have completed the survey.
The final number is the one that is going to be used when checking message distribution in comparison with demographic data and Reg Focus

```{r Messages, echo = FALSE,}

summary(data$Got_Msgs)

received_msgs <- received_msgs %>%
  mutate( Msg_Type = as.factor( Msg_Type),
         Message_Group = as.factor(Message_Group),
         Country = as.factor(Country),
         Reg_Orientation_Cat = as.factor(Reg_Orientation_Cat))

summary(received_msgs %>% dplyr::select(Msg_Type, Message_Group,Nmbr_Msgs_Sent, Nmbr_Msgs_Seen))

```


From the summery, we can see that messages were distributed equally between the three sent types, there is discrepancy of when the users started their messaging treatment.
**As the current data has is still incomplete as the treatment continues** the minimum number of messages received is 3 and the maximum is 13 since some users have received a repeated message.
The number of messages seen (the user pressed on the message and entered the app to read it as a whole) varies with some not checking any and other all the messages, with the mean being **4.5** messages 


### Distribution of Message Type
For all those who received messages first and then for only those who completed the survey

```{r Message Disrtibution, echo = FALSE}
data %>%
  filter(Got_Msgs == TRUE) %>%
  ggplot(aes(x = Msg_Type)) +
  geom_bar(fill = "skyblue", show.legend = FALSE) +
  geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5) +
  labs(y = "Number of Users",
       x = "Message Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

data %>%
  filter(Got_Msgs == TRUE, Complt_Survey == TRUE) %>%
  ggplot(aes(x = Msg_Type)) +
  geom_bar(fill = "skyblue", show.legend = FALSE) +
  geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5) +
  labs(y = "Number of Users",
       x = "Message Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

The messages types have been distributed equally, however when considering comparing it to demographic variables, we have to keep in mind that not all of those who received messages have completed the survey. Those have completed the survey were by more likely to get a neutral message followed by promotion and then prevention.

### Message Type Distribution By Gender
```{r Messaging Dis Gender, echo = FALSE}
survey_completed %>%
  filter(Gender %in% c("Male", "Female")) %>%
  group_by(Msg_Type, Gender) %>%
  summarise(count = n(), .groups = 'drop_last') %>%
  group_by(Msg_Type) %>%
  mutate(proportion = count / sum(count)) %>% 
  ggplot(aes(x = Msg_Type, y = proportion, fill = Gender)) +
  geom_bar(stat = "identity", position = "stack") +
  geom_text(aes(label = scales::percent(proportion, accuracy = 1)), 
            position = position_stack(vjust = 0.5), color = "white", size = 3.5) +
  labs(y = "Percentage", x = "Message Type", fill = "Gender") +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format(scale = 100, accuracy = 10)) +
  scale_fill_brewer(palette = "Set1")
```
Message Types seem to have been sent to similar proportions of users when considering Gender

### Message Type Distribution By Age
```{r Messaging Dis Age, echo = FALSE}
survey_completed %>%
  group_by(Msg_Type, Age_Group) %>%
  summarise(count = n(), .groups = 'drop_last') %>%
  group_by(Msg_Type) %>%
  mutate(proportion = count / sum(count)) %>% 
  ggplot(aes(x = Msg_Type, y = proportion, fill = Age_Group)) +
  geom_bar(stat = "identity", position = "stack") +
  geom_text(aes(label = scales::percent(proportion, accuracy = 1)), 
            position = position_stack(vjust = 0.5), color = "white", size = 3.5) +
  labs(y = "Percentage", x = "Message Type", fill = "Age Group") +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format(scale = 100, accuracy = 10)) +
  scale_fill_brewer(palette = "Set1")
```
By chance neutral messages have been sent to *18-25** year olds at a higher rate than prevention or promotion messages, the percentage of **36-48** year olds who have received a promotion message is also higher than others.


### Message Type Distribution By Citizen Scientist Regulatory Orientation Catagory
```{r Messaging Dis Reg Orientation Cat, echo = FALSE}
survey_completed %>%
  filter(!is.na(Reg_Orientation_Cat)) %>%
  group_by(Msg_Type, Reg_Orientation_Cat) %>%
  summarise(count = n(), .groups = 'drop_last') %>%
  group_by(Msg_Type) %>%
  mutate(proportion = count / sum(count)) %>% 
  ggplot(aes(x = Msg_Type, y = proportion, fill = Reg_Orientation_Cat)) +
  geom_bar(stat = "identity", position = "stack") +
  geom_text(aes(label = scales::percent(proportion, accuracy = 1)), 
            position = position_stack(vjust = 0.5), color = "white", size = 3.5) +
  labs(y = "Percentage", x = "Message Type", fill = "Regulatory Orientation") +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format(scale = 100, accuracy = 10)) +
  scale_fill_brewer(palette = "Set1")
```
The distribution seems mostly similar. Interestingly, by chance less neutral oriented users out of the 24 seem to have been randomly chosen to get neutral messages

### Message Type Distribution By Partcipation Year
```{r Messaging Dis Partcipation Year, echo = FALSE}
survey_completed %>%
  filter(!is.na(Msg_Type), !is.na(Participation_Date)) %>%
  filter(Participation_Date %in% c('2023', '2022', '2021', '2020', '2019')) %>%
  group_by(Msg_Type, Participation_Date) %>%
  summarise(count = n(),.groups = 'drop_last') %>%
  group_by(Msg_Type) %>%
  mutate(proportion = count / sum(count)) %>% 
  ggplot(aes(x = Msg_Type, y = proportion, fill = factor(Participation_Date))) +
  geom_bar(stat = "identity", position = "stack") +
  geom_text(aes(label = scales::percent(proportion, accuracy = 1)), 
            position = position_stack(vjust = 0.5), color = "white", size = 3.5) +
  labs(y = "Percentage", x = "Message Type", fill = "Participation Date") +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format(scale = 100, accuracy = 10)) +
  scale_fill_brewer(palette = "Set1")
```
Average year of participation seems mostly similar.

### Message Type Messaging Group
```{r Messaging by Group, echo = FALSE}
survey_completed %>%
  filter(!is.na(Msg_Type), !is.na(Message_Group)) %>%
  group_by(Msg_Type, Message_Group) %>%
  summarise(count = n(),.groups = 'drop_last') %>%
  group_by(Msg_Type) %>%
  mutate(proportion = count / sum(count)) %>% 
  ggplot(aes(x = Msg_Type, y = proportion, fill = Message_Group)) +
  geom_bar(stat = "identity", position = "stack") +
  geom_text(aes(label = scales::percent(proportion, accuracy = 1)), 
            position = position_stack(vjust = 0.5), color = "white", size = 3.5) +
  labs(y = "Percentage", x = "Message Type", fill = "Message Group") +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format(scale = 100, accuracy = 10)) +
  scale_fill_brewer(palette = "Set1")
```
Message types also seem to have been distributed similarly for different messaging groups (time of start for messaging)



## Messages Seen
Seeing that the message types were distributed mostly equally, we move on to check if the users who received them, have opened the app to read the complete text at a similar rate. From now on we will (unless mentioned otherwise) consider all those that have receieved messages and not only those that have fully completed the survey.

### Average number of Messages Seen
```{r Average seen messages, echo = FALSE}
data %>%
  filter(Got_Msgs) %>%
  ggplot(aes(x = Msg_Type, y = Nmbr_Msgs_Seen, fill = Msg_Type)) + 
  geom_bar(stat = "summary", fun = "mean", position = "dodge") +
  theme_minimal() +
  labs(title = "All Those That Received Messages",
       x = "Message Type",
       y = "Average Messages Seen") +
  scale_fill_brewer(palette = "Set1") + 
  geom_text(stat = "summary", fun = mean, aes(label = sprintf("%.2f", ..y..)), position = position_dodge(width = 0.9), vjust = -0.5) 

data %>%
  filter(Complt_Survey) %>%
  ggplot(aes(x = Msg_Type, y = Nmbr_Msgs_Seen, fill = Msg_Type)) + 
  geom_bar(stat = "summary", fun = "mean", position = "dodge") +
  theme_minimal() +
  labs(title = "For Those That Recieved Messages and Completed Survey",
       x = "Message Type",
       y = "Average Messages Seen") +
  scale_fill_brewer(palette = "Set1") + 
  geom_text(stat = "summary", fun = mean, aes(label = sprintf("%.2f", ..y..)), position = position_dodge(width = 0.9), vjust = -0.5) 
```

From the average number of messages seen, we can see that the average rate is higher for promotion messages **4.95** than neutral **4.56**, and finally prevention messages having the lowest reception **4.03**.
Note that when comparing the averages  for only those who have completed the entire survey, the number is average number of read messages is lower for all types.

### ANOVA
```{r Average seen messages ANOVA, echo = TRUE}
anova_result <- aov(Nmbr_Msgs_Seen ~ Msg_Type, data = data %>% filter(Got_Msgs))
summary(anova_result)
rm(anova_result)
```

Doing a quick anova test shows that the there is no significant difference for the difference in messages seen with a P value of **0.467**.


As for a thorougher look at the difference of message seen between those who completed the survey and those who have not.
splitting the groups into two shows that those who have not  completed the survey were more likely to later enter the app and read the complete message (check the bar graph below). Keeping in mind that the number of those who did not complete the survey after giving approval for messaging is low

```{r Average seen messages considering completion of survey, echo = FALSE}
data %>%
  filter(Got_Msgs) %>%
  mutate(Survey_Status = ifelse(Complt_Survey, "Completed", "Not Completed")) %>%
  group_by(Survey_Status, Msg_Type) %>%
  summarise(Avg_Msgs_Seen = mean(Nmbr_Msgs_Seen, na.rm = TRUE), .groups = 'drop') %>%
  ggplot(aes(x = Msg_Type, y = Avg_Msgs_Seen, fill = Survey_Status)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Comparison of Messages Seen Between Survey Responders and Non-Responders",
       x = "Message Type",
       y = "Average Number of Messages Seen") + 
  scale_fill_brewer(palette = "Set1") +
  geom_text(aes(label = sprintf("%.2f", Avg_Msgs_Seen)), position = position_dodge(width = 0.9), vjust = -0.5)
```

### Average Percentage of Messages Seen Out of Sent When Considering Messages Type
```{r Average seen messages considering sent, echo = FALSE}
data %>%
  filter(Got_Msgs) %>%
  ggplot(aes(x = Msg_Type, y = (Nmbr_Msgs_Seen / Nmbr_Msgs_Sent) *100, fill = Msg_Type)) + 
  geom_bar(stat = "summary", fun = "mean", position = "dodge") +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(x = "Message Type",
       y = "Average Messages Seen") +
  scale_fill_brewer(palette = "Set1") + 
  geom_text(stat = "summary", fun = mean, aes(label = sprintf("%.2f", ..y..)), position = position_dodge(width = 0.9), vjust = -0.5) # Added to display the mean value on top of each bar

#checking if there is a significant difference
anova_result <- aov((Nmbr_Msgs_Seen / Nmbr_Msgs_Sent) * 100 ~ Msg_Type, data = data)
summary(anova_result)
rm(anova_result)
```

Considering that the treatment has not finished for some of the citizen scientists, we check the average rate of messages read when considering the number of messages sent per user.

Although the P Value drops, the difference is still insignificant.


###  Catagorisation of Messages seen considering Message Type
```{r Average seen messages as catagory, echo = FALSE}
data %>%
  filter(Got_Msgs) %>%
  mutate(seen_category = cut(Nmbr_Msgs_Seen,
                             breaks = c(-1, 0, 4, 8, Inf), 
                             labels = c("0 messages", "1-4 messages", "5-8 messages", "9+ messages"),
                             right = TRUE)) %>%
  ggplot(aes(x = Msg_Type, fill = seen_category)) + 
  geom_bar(position = "dodge") +
  geom_text(stat = 'count', aes(label = ..count..), position = position_dodge(width = 1), vjust = -0.5) +
  theme_minimal() +
  labs(x = "Message Group",
       y = "Number of Users") +
  scale_fill_brewer(palette = "Set1", name = "Messages Seen") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```
Looking at rates of messages seen as a category we see that the number of users, who checked 5-8 messages is almost identical between message types, while promotion messages have a higher rate of users that have seen at least a single message.



### Average Number of Seen Messages by Citizen Scientist Regulatory Focus and Message Type
```{r Average seen messages considering Regulatory Focus and Message Type, echo = FALSE}
data %>%
  filter(Got_Msgs, !is.na(Reg_Orientation_Cat)) %>%
  group_by(Reg_Orientation_Cat, Msg_Type) %>%
  summarise(Avg_Msgs_Seen = mean(Nmbr_Msgs_Seen, na.rm = TRUE), .groups = 'drop') %>%
  ggplot(aes(x = Reg_Orientation_Cat, y = Avg_Msgs_Seen, fill = Msg_Type)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(x = "Regulatory Focus Category",
       y = "Average Number of Messages Seen") +
  scale_fill_brewer(palette = "Set1") +
  geom_text(aes(label = sprintf("%.2f", Avg_Msgs_Seen)), position = position_dodge(width = 0.9), vjust = -0.5)
```
Moving Back to Averages we see that users were more likely to read the messages that were designed for their specific orientation (even though the difference for promotion orientation is mild when comparing with neutral messes.)
From a glance, it can be deduced that prevention oriented messages are maintain the interest of prevention  oriented users, while neutral and promotion oriented messages might be more universal.


### ANOVA (not sure correct, logistic regression can be done with data set that has all messges and all reports.)
```{r Average seen messages considering Regulatory Focus and Message Type ANOVA, echo = TRUE}
test <- survey_completed %>%
  filter(!is.na(Reg_Orientation_Cat)) %>%
  group_by(Reg_Orientation_Cat, Msg_Type) %>%
  summarise(Avg_Msgs_Seen = mean(Nmbr_Msgs_Seen, na.rm = TRUE), .groups = 'drop') %>%
  aov(Avg_Msgs_Seen ~ Reg_Orientation_Cat + Msg_Type + Reg_Orientation_Cat:Msg_Type, data = .)
summary(test)
rm(test)
```

### Considering Messaging Groups

We´ve checked earlier if the message types had equal proportions of participants from different groups, but before we check if the different groups have seen the messages at a similar rate lets check the distribution of users between different groups ie different messaging treatment start date
```{r Message Groups Distribution, echo = FALSE}
data %>% subset(Got_Msgs == TRUE) %>% 
  ggplot(aes(x = Message_Group)) +
  geom_bar(fill = "skyblue") + 
  geom_text(stat='count', aes(label=..count..), vjust=-0.5) + 
  labs(y = "Count",
       x = "Message Type") +
  theme_minimal()
```
We see that the we´ve had a strong initial start, a drop at the beginning of July, and then another rise after fixing the push notification of the invites.
Note that for future mosquito seasons, having the push notification functional with initial invites should yield better participation in surveys


### Average Message Reading Rate by Message Group

```{r Average seen messages for Groups, echo = FALSE}
data %>%
  filter(Got_Msgs) %>%
  ggplot(aes(x = Message_Group, y = Nmbr_Msgs_Seen, fill = Message_Group)) +
  geom_bar(stat = "summary", fun = "mean") +
  theme_minimal() +
  labs(title = "Average Message Reading Rate by Message Group",
       x = "Message Group",
       y = "Average Messages Seen") +
  scale_fill_brewer(palette = "Set1", guide = "none") + 
  geom_text(stat = "summary", fun = mean, aes(label = sprintf("%.2f", ..y..)), position = position_dodge(width = 0.9), vjust = -0.5)
```

When checking the interest rate of the messaging groups through the reate of seeing messages, we see that that the initial wave is the lowest, and the one From the first half of August stands out with a higher rate. We should note that the final 2 groups have not completed their treatment by the time of acquiring the data sets.


### Average Message Reading Rate by Message Group Catagory

```{r proportion of seen messages for each Groups, echo = FALSE}
data %>%
  filter(Got_Msgs) %>%
  mutate(seen_category = cut(Nmbr_Msgs_Seen,
                             breaks = c(-1, 0, 4, 8, Inf), 
                             labels = c("0 messages", "1-4 messages", "5-8 messages", "9+ messages"),
                             right = TRUE)) %>%
  group_by(Message_Group, seen_category) %>%
  summarise(count = n(), .groups = "drop_last") %>%
  mutate(percentage = count / sum(count) * 100) %>%
  ggplot(aes(x = Message_Group, y = percentage, fill = seen_category)) + 
  geom_bar(stat = "identity", position = "stack") +
  geom_text(aes(label = scales::percent(percentage/100, accuracy = 1)), 
            position = position_stack(vjust = 0.5), color = "Black", size = 2.5) +
  theme_minimal() +
  labs(x = "Message Group",
       y = "Percentage of Users") +
  scale_fill_brewer(palette = "Set3", name = "Messages Seen") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Checking the proportions by message seen category we notice that the initial respondents had a very high rate of users that have not entered the application to read completely any of the messages.



## Reports

### Report Distribution
Since the update of the **270,892** registered citizen scientists **45670** of them have filled  at least **1** report and were responsible for a total of **147123** reports, of which **218** have completed the survey.


```{r Reports, echo = FALSE}
sum(data$Total_Rprts_Filled)
count(data %>% filter(Total_Rprts_Filled >= 1))

summary(data %>% dplyr::select(Total_Rprts_Filled, Rprts_Filled_2022, Rprts_Filled_2023, Season_Rprts_Filled_2023))
```
Checking the summary of the reports filled we see that the fact that the majority of registered citizen scientists do not fill a single report, heavily impacts of reducing the number of reports, where according the to the mean, it should be double if every registrar completes only one report. A further segmented look at user reporting behavior might be useful to assess outlines


### Segmented distribution

```{r Segmented Distribution, echo = FALSE}



data %>%
  mutate(Total_Rprts_Segment = cut(Total_Rprts_Filled,
                                   breaks = c(-1, 0, 1, 10, 50, Inf),
                                   labels = c("0 reports", "1 report", "2-10 reports", "11-50 reports", "50+ reports"),
                                   right = TRUE)) %>%
  ggplot(aes(x = Total_Rprts_Segment, group = Total_Rprts_Segment)) +
  geom_bar(fill = "skyblue") +
  geom_text(stat = 'count', aes(label = scales::percent(..count../sum(..count..))), vjust = -0.5) +
  labs(y = "Number of Users", x = "Total Reports Filled") +
  theme_minimal()


data %>%
  mutate(Seasonal_Total_Rprts_Segment = cut(Season_Rprts_Filled_2023,
                                            breaks = c(-1, 0, 1, 10, 50, Inf),
                                            labels = c("0 reports", "1 report", "2-10 reports", "11-50 reports", "50+ reports"),
                                            right = TRUE)) %>%
  ggplot(aes(x = Seasonal_Total_Rprts_Segment)) +
  geom_bar(fill = "coral") +
  geom_text(stat = 'count', aes(label = scales::percent(..count../sum(..count..))), vjust = -0.5) +
  labs(y = "Number of Users", x = "Seasonal Reports Filled 2023") +
  theme_minimal()


data %>%
  filter(year(Registered_Participation_Date) == 2022) %>%
  mutate(Rprts_Filled_2022_Segment = cut(Rprts_Filled_2022,
                                         breaks = c(-1, 0, 1, 10, 50, Inf),
                                         labels = c("0 reports", "1 report", "2-10 reports", "11-50 reports", "50+ reports"),
                                         right = TRUE)) %>%
  ggplot(aes(x = Rprts_Filled_2022_Segment)) +
  geom_bar(fill = "coral") +
  geom_text(stat = 'count', aes(label = scales::percent(..count../sum(..count..))), vjust = -0.5) +
  labs(y = "Number of Users", x = "Reports Filled in 2022") +
  theme_minimal()

```

When considering all those who registered since the update we see that its not even **50/50** split, but  **83%** of the users actually have not filled a single report over the years, and when considering reports filled within the mosquito season of 2023, the rate becomes close to **95%** of users, seeing that a lot of 1 time participants have already become inactive.

To be more specific, and exclude the impact of users who might have signed up in the middle or even after the end of the 2023 season, and avoid the added impact of long registered inactive users, we look in the third and final chart, at the users who have registered in 2022 and only reports that were filled by them in 2022, Still we see that similar to the graph considering all the registered citizen scientists, out of **63,766** Citizen Scientists who registered in 2022, **55,349** or more than **86%**, have not filled a single report.

The mean number of reports filled for the year, **0.1164** reports per citizen scientist, was skewed by **0.03%** of the participants that filled more than 50 reports and **0.53%** that filled more than 10 reports.

This makes clear two things for the future of the project and analysis.
The first step should be to push those who do not participate at all to fill at least 1 report, and in the case of the experiment, check if messaging has had any significant impact in doing that.
The importance of excluding outliers before considering changes in averages


### Segmented Distribution, Message Receivers
```{r Seg Distribution Messaged, echo = FALSE}
received_msgs %>%
  mutate(Total_Rprts_Segment = cut(Total_Rprts_Filled,
                                   breaks = c(-1, 0, 1, 10, 50, Inf),
                                   labels = c("0 reports", "1 report", "2-10 reports", "11-50 reports", "50+ reports"),
                                   right = TRUE)) %>%
  ggplot(aes(x = Total_Rprts_Segment, group = Total_Rprts_Segment)) +
  geom_bar(fill = "skyblue") +
  geom_text(stat = 'count', aes(label = scales::percent(..count../sum(..count..))), vjust = -0.5) +
  labs(y = "Number of Users", x = "Total Reports Filled") +
  theme_minimal()+
  geom_text(stat='count', aes(label=..count..), position=position_stack(vjust = 0.0001), size=3)



received_msgs %>%
  mutate(Rprts_Filled_Season_Segment = cut(Season_Rprts_Filled_2023,
                                         breaks = c(-1, 0, 1, 10, 50, Inf),
                                         labels = c("0 reports", "1 report", "2-10 reports", "11-50 reports", "50+ reports"),
                                         right = TRUE)) %>%
  ggplot(aes(x = Rprts_Filled_Season_Segment)) +
  geom_bar(fill = "coral") +
  geom_text(stat = 'count', aes(label = scales::percent(..count../sum(..count..))), vjust = -0.5) +
  labs(y = "Number of Users", x = "Reports Filled in 2023 Season") +
  theme_minimal() +
  geom_text(stat='count', aes(label=..count..), position=position_stack(vjust = 0.0001), size=3)


received_msgs %>%
  filter(year(Registered_Participation_Date) == 2022) %>%
  mutate(Rprts_Filled_2022_Segment = cut(Rprts_Filled_2022,
                                         breaks = c(-1, 0, 1, 10, 50, Inf),
                                         labels = c("0 reports", "1 report", "2-10 reports", "11-50 reports", "50+ reports"),
                                         right = TRUE)) %>%
  ggplot(aes(x = Rprts_Filled_2022_Segment)) +
  geom_bar(fill = "coral") +
  geom_text(stat = 'count', aes(label = scales::percent(..count../sum(..count..))), vjust = -0.5) +
  labs(y = "Number of Users", x = "Reports Filled in 2022 (By Participants Registerd in 2022)") +
  theme_minimal() +
  geom_text(stat='count', aes(label=..count..), position=position_stack(vjust = 0.0001), size=3)

```

When Considering the participants that have receive messages, it becomes clear that those who have responded to the survey request are mostly those who are considered frequent users, with a drastic change of distribution when considering all reports filled, as all of them have at least filled a single report, and the segment who is 50+ all time reports makes up almost **20%**. 

The differences are similar in the case of seasonal reports for 2023, where although we start seeing users who have received messages failing to fill reports, the rate is much lower than the general population of participants. This is also true when checking the segmentation of only the participants who have signed up/registered in 2022 filled  and reports they filled in 2022.


### Demographic Distribution
```{r Report Demographic , echo = FALSE}

survey_completed %>% 
  filter(Gender %in% c("Male", "Female")) %>% 
ggplot(aes(x = Gender, fill = Total_Rprts_Segment)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = percent_format(), limits = c(0, 1)) +
  scale_fill_brewer(palette = "Set3") +
  labs(y = "Percentage of Users", x = "Age Group", fill = "Reports Segment") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  geom_text(stat='count', aes(label=..count..), position=position_fill(vjust = 0.5), size=3)



survey_completed %>% 
  ggplot(aes(x = Age_Group, fill = Total_Rprts_Segment)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = percent_format(), limits = c(0, 1)) +
  scale_fill_brewer(palette = "Set3") +
  labs(y = "Percentage of Users", x = "Age Group", fill = "Reports Segment") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  geom_text(stat='count', aes(label=..count..), position=position_fill(vjust = 0.5), size=3)
```

A quick view of the volume of total reporting of different demographic segments, assessing only those who completed the survey.

### Chronological Distribution


```{r Report Chronological , echo = FALSE}
ggplot(data = reports_data %>%
         mutate(Rprt_Date = as.Date(Rprt_Date)) %>%
         filter(year(Rprt_Date) >= 1900 & year(Rprt_Date) <= 2262) %>%
         count(Month = floor_date(Rprt_Date, "month"))) +
  geom_bar(aes(x = Month, y = n), stat = "identity", fill = "skyblue") +
  scale_x_date(date_breaks = "1 month", date_labels = "%b %Y") +
  labs(title = "Monthly Report Counts",
       x = "Month",
       y = "Number of Reports") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


ggplot(data = reports_data %>%
         mutate(Rprt_Date = as.Date(Rprt_Date), 
                Year = year(Rprt_Date), 
                Week = week(Rprt_Date)) %>%  
         filter(Year == 2021) %>%
         count(Week)) +
  geom_bar(aes(x = Week, y = n), stat = "identity", fill = "steelblue") +
  scale_x_continuous(breaks = seq(1, 52, by = 2)) +  
  labs(title = "Weekly Report Distribution in 2021",
       x = "Week Number",
       y = "Number of Reports") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, vjust = 0.5, hjust=1, size = 7))

ggplot(data = reports_data %>%
         mutate(Rprt_Date = as.Date(Rprt_Date), 
                Year = year(Rprt_Date), 
                Week = week(Rprt_Date)) %>%  
         filter(Year == 2022) %>%
         count(Week)) +
  geom_bar(aes(x = Week, y = n), stat = "identity", fill = "steelblue") +
  scale_x_continuous(breaks = seq(1, 52, by = 2)) +  
  labs(title = "Weekly Report Distribution in 2022",
       x = "Week Number",
       y = "Number of Reports") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, vjust = 0.5, hjust=1, size = 7))


ggplot(data = reports_data %>%
         mutate(Rprt_Date = as.Date(Rprt_Date), 
                Year = year(Rprt_Date), 
                Week = week(Rprt_Date)) %>%  
         filter(Year == 2023) %>%
         count(Week)) +
  geom_bar(aes(x = Week, y = n), stat = "identity", fill = "steelblue") +
  scale_x_continuous(breaks = seq(1, 47, by = 2)) +  
  labs(title = "Weekly Report Distribution in 2023",
       x = "Week Number",
       y = "Number of Reports") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, vjust = 0.5, hjust=1, size = 7))
```

Based on the volume of reporting throughout the years, the Mosquito Season can be consdiered to be roughly between 01/05 and 31/10





# Siginificance Testing


## Participant Regulatory Orientation

To check if the distribution of regulatory focus scores of participants is significantly different we conduct a one-sample t-test to compare the mean of the sample to the average regulatory focus mean of a general population.

```{r Participant Regulatory Orientation  , echo = TRUE, warning=FALSE}
mean_reg_orientation <- mean(survey_completed$Reg_Orientation, na.rm = TRUE)
t_test_result <- t.test(survey_completed$Reg_Orientation, mu = 0, na.rm = TRUE)
mean_reg_orientation
t_test_result
rm(mean_reg_orientation, t_test_result)
```
The average regulatory focus of the participant pool that responded to the survey was significantly different than the norm, generally considered to be neutral population-wide, with a tendency of western countries to be more promotion oriented and yield a positive average, the t-test comparing the survey result to that the population yielded a t-statistic equal to to **-4.3** with 215 degrees of freedom, and with a p-value of **2.524e-05** well below the significance threshold, indicating that the mean regulatory orientation for users who completed the survey is significantly different from 0 and more Prevention oriented.

**The alternative hypothesis, which posits that the true mean is not equal to zero, is supported by the data**

```{r Participant Regulatory Orientation Vis, echo = FALSE, warning=FALSE}
ggplot(survey_completed, aes(x = Reg_Orientation)) +
  geom_histogram(aes(y = ..density..), binwidth = 1, fill = "steelblue", alpha = 0.7) +
  geom_density(color = "#b4464b") +
  geom_vline(xintercept = -1.402778, color = "#82b446", linetype = "dashed") +
  geom_vline(xintercept = -2.0448547, color = "#b47846", linetype = "dashed") +
  geom_vline(xintercept = -0.7607009, color = "#b47846", linetype = "dashed") +
  annotate("text", x = -1.402778, y = Inf, label = "Mean (-1.40)", vjust = 0.8, color = "#82b446", size = 3) +
  annotate("text", x = -2.0448547, y = Inf, label = "Lower CI (-2.04)", vjust = 2,hjust = 1.2, color = "#b47846", size = 3) +
  annotate("text", x = -0.7607009, y = Inf, label = "Upper CI (-0.76)", vjust = 2, hjust = -0.3, color = "#b47846", size = 3) +
  labs(title = "One Sample t-test Result Visualization",
       x = "Reg Orientation Value",
       y = "Density") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, vjust = 0.5, hjust = 1, size = 7))

```


To move beyond averages and check the distribution of the pool of participants that answered the survey, based on their regulatory focus orientation (regardless if mild or extreme), the count of users on each side was analysed. A direct comparison of users that have been deemed by the test either to be of either promotion or prevention orientation has been done through a Chi-squared test, to determine  whether the distribution of users deviated significantly from a uniform distribution.

```{r Participant Regulatory Orientation participants  , echo = TRUE, warning=FALSE}
oriented_data <- subset(survey_completed, Reg_Orientation_Cat %in% c('Prevention', 'Promotion'))
oriented_counts <- table(oriented_data$Reg_Orientation_Cat)
oriented_counts <- oriented_counts[names(oriented_counts) != "Neutral"]
oriented_counts

# Since we expect the counts to be equal, the expected frequency for each is half of the total count
total_expected_count <- sum(oriented_counts)
expected_counts <- rep(total_expected_count / 2, 2)

chi_squared_test <- chisq.test(oriented_counts, p = rep(1/2, 2))
print(chi_squared_test)

rm(orientation_counts, chi_squared_test, oriented_data, oriented_counts, total_expected_count, expected_counts)
```

The test yielded a chi-squared statistic equal to **14.083** and a p-value of **0.00017** suggesting  a significant association or difference in the users' regulatory orientation categories significantly different from a uniform one.




## Participant Motivation Rating
We took a quick look done during the descriptive analysis at the distribution of motivation ratings of the survey participants. To take a deeper look an ANOVA test was done to assesses whether there are statistically significant differences in the mean ratings across the different higher order motivator categories.

### ANOVA Difference Between Ratings of Different Motivators
```{r Participant Motivation ANOVA, echo = TRUE}
motivator_ratings <- survey_completed %>%
  dplyr::select(Openness_To_Change, Self_Enhancement, Continuity, Self_Transcendence, Security, Teaching) %>%
  pivot_longer(cols = everything(), names_to = "Motivator", values_to = "Rating")%>%
  drop_na(Rating)
 
anova_result <- aov(Rating ~ Motivator, data = motivator_ratings)
summary(anova_result)
```

The analysis revealed a highly significant difference among the ratings of five motivators; **(F(5, 1298) = 356, p < 2e-16)**. 

To further get detailed insights into the differences between various motivators post-hoc analysis with Tukey's Honest Significant Difference (HSD) test was done, and only the significant differences dplyr::selected to be showcased. Furthermore effect size was measured using Cohen's d to standardize the difference between the means.


### Post-Hoc Analysis
```{r Participant Motifvation Tukey, echo = TRUE}
if (summary(anova_result)[[1]][["Pr(>F)"]][1] < 0.05) {
  tukey_result <- TukeyHSD(anova_result)
  print(tukey_result)
}

SD_pooled <- sqrt(sum(anova_result$residuals^2) / anova_result$df.residual)

means <- tapply(motivator_ratings$Rating, motivator_ratings$Motivator, mean)
cohen_d_security <- sapply(means, function(x) (means['Security'] - x) / SD_pooled)
cohen_d_self_transcendence <- sapply(means, function(x) (means['Self_Transcendence'] - x) / SD_pooled)
cohen_d_Openness_To_Change <- sapply(means, function(x) (means['Openness_To_Change'] - x) / SD_pooled)
cohen_d_security
cohen_d_self_transcendence
cohen_d_Openness_To_Change
rm(motivator_ratings, anova_result, tukey_result, SD_pooled, means, cohen_d_security, cohen_d_self_transcendence, cohen_d_Openness_To_Change)
```
Tukey HSD test and Cohen's d analysis highlighted several significant and large differences. Notably, both Security and Self Transcendence demonstrated significant differences  when compared to Continuity and Self Enhancement. Openness to Change has also shown a significantly higher effect size when compared with Self Enhancement and Continuity, however it was also significantly lower when compared to Security and Self Transcendence, suggesting they are more influential in shaping the participants actions. In very simplified terms, the findings suggest that apprehension and altruism might be more important to the citizen scientists Participating in Mosquito Alert than the novelty of approach.



## Impact of Regulatory Focus on Motivation Ratings

Considering that Regulatory focus theory suggests that those with a prevention focus are  more likely to be motivated by safety, security, and responsibility, we attempt to see if variation of regulatory focus among those who completed the survey has a significant impact on the rating they have given various motivators.


We start off by completing a series of One-way ANOVAs, to treat each motivator as a separate dependent variable

### ANOVA of Reg Focus Impact on Rating Motivators
```{r Reg Orientation Motivation ANOVA ALL Test, echo = TRUE, results='hide' }
motivator_columns <- c("Continuity", "Self_Enhancement", "Self_Transcendence", "Security", "Openness_To_Change", "Teaching")

for (motivator in motivator_columns) {
  formula <- as.formula(paste(motivator, "~ Reg_Orientation_Cat"))
  anova_result <- aov(formula, data = survey_completed)
  cat("\nANOVA results for", motivator, ":\n")
  print(summary(anova_result))
  cat("\n")
}

```

The results show that the only significant results was the difference in the way Security as a motivator was rated by participants with varying regulatory focus orientation (F(2, 212) = 3.528, p = 0.0311). There was a marginally significant main effect for Self Transcendence as well (F(2, 212) = 2.664, p = 0.072), suggesting a possible influence, however, not strong enough to be considered statistically significant.

To further analyse the variation for Security we complete the One-Way ANOVA and complete Tukey multiple comparisons of means
  
### ANOVA of Reg Focus Impact on Security as Motivator and Post Hoc  
```{r Reg Orientation Motivation Anova Test, echo = TRUE}
anova_result <- aov(Security ~ Reg_Orientation_Cat, data = survey_completed)
summary(anova_result)

if (summary(anova_result)[[1]][["Pr(>F)"]][1] < 0.05) {
  tukey_result <- TukeyHSD(anova_result)
  print(tukey_result)
}

rm(anova_result, motivator_columns)
```

The Tukey test suggests that there might be a marginal difference in Security scores between Prevention-oriented and Neutral or Promotion, with those with prevention orientation rating it higher, but no significant differences were found.



To take a closer look and look at the variation between Promotion and Prevention orientations specifically, we subset the data to complete a Welch Two Sample t-test. 

### T-test of Reg Focus Impact on Rating Security
```{r Reg Orientation Motivation T-test, echo = TRUE}
subset_data <- survey_completed[survey_completed$Reg_Orientation_Cat %in% c("Prevention", "Promotion"), ]

t_test_results <- t.test(Security ~ Reg_Orientation_Cat, data = subset_data)
print(t_test_results)

rm(subset_data)
```

Again, while we see a numerical difference in the mean Security scores between Prevention-oriented and Promotion-oriented individuals, this difference is not statistically significant.

**The null hypothesis, which posits that the there is no difference in the rating of security based on Reg Focus Orientation, is supported by the data**


## Impact of Messaging


### Yearly/Seasonal Average Difference Analysis

To consider the impact of sending messages to users on their activity and completion of reports. The first thing we check is the change in average number of reports completed by users that were part of the experiment and received messages, and have been registered citizen scientists for at least 2 years, allowing them in principle to fill reports in different mosquito seasons/years.

To measure the difference in reporting averages we complete a series of paired t-tests. 

```{r Report Message Seasonal Average, echo = TRUE}

paired_t_test_result <- received_msgs %>%
  filter(Registered_Participation_Date < as.Date('2023-01-01')) %>%
  with(t.test(Season_Rprts_Filled_2023, Season_Rprts_Filled_2022, paired = TRUE))
print(paired_t_test_result)

paired_t_test_result <- received_msgs %>%
  filter(Registered_Participation_Date < as.Date('2022-01-01')) %>%
  with(t.test(Season_Rprts_Filled_2022, Season_Rprts_Filled_2021, paired = TRUE))
print(paired_t_test_result)

paired_t_test_result <- data %>%
  filter(Registered_Participation_Date < as.Date('2023-01-01')) %>%
  filter(!User_ID %in% received_msgs$User_ID) %>% 
  with(t.test(Season_Rprts_Filled_2023, Season_Rprts_Filled_2022, paired = TRUE))
print(paired_t_test_result)

rm(paired_t_test_result)
```

In a paired t-test comparing the 2023 and 2022 seasons for the participants that have received messages in 2023 and were registered before 2023, a significant mean difference of approximately 12 additional reports was found **(t = 2.9778, df = 140, p-value = 0.003113)**. The 95% confidence interval ranging from **4.1 to 20.1** additional reports.

When repeating the test to compare 2022 and 2021 seasons for the users received messages in 2023 and were registered before 2022, the outcome was different with a non-significant **-0.49** decrease in average number of reports; **(t = -0.12358, df = 70, p-value = 0.902)**.

More importantly comparing the 2023 and 2022 seasons, for all participants bar the ones who were part of the experiment and were registered before 2023, we see a statistically significant drop **(-0.11)** in average number of reports (t = -26.032, df = 186646, p-value < 2.2e-16)

as with the second and third t-tests, it is usual to see that the number of reports reduce on average for the same participants over time, due to attrition and loss of interest.
The fact that the average has increased for those who received messages is promising.


We continue with further analysis. 


### Difference-in-Differences Analysis

In order to assess the change in participant behavior during the period of messaging, we compare the number of reports filled by participants before, during and after their respective messaging period. Note that since the users are distributed in the date they recived the first message and the time frame in which they received messages, seasonality is better accounted for.
The number of reports for each user and each specific period was calculated by measuring the specific days in between which the specific participant received messages and then adding the number of reports in exactly the same amount of days before and after the first and last message respectively

```{r Report Dif-in-Dif, echo = TRUE}

paired_t_test_result <- with(received_msgs, t.test(Rprts_During_Msging, Rprts_Before_Msging,  paired = TRUE))
print(paired_t_test_result)

paired_t_test_result <- with(received_msgs, t.test(Rprts_During_Msging, Rprts_After_Msging,  paired = TRUE))
print(paired_t_test_result)

paired_t_test_result <- with(received_msgs, t.test(Rprts_After_Msging, Rprts_After_Msging,  paired = TRUE))
print(paired_t_test_result)

```

When comparing the average number of reports filled by the users that participated in the experiment, before during and after receiving messages.
we find a significant increase in the mean number of reports during messaging when compared to before **(2.68)** **p= 0.01** as well as a non significant increase  **(1.59)** **p= 0.09** when comparing to after the duration.

The participants seem to keep reporting at a higher rate after the messaging period  is concluded when compared to before **(1.09)** **p= 0.47** the messaging period but the difference is not significant.



### Time-Series Analysis.

One final check about the impact of messaging on reporting behavior can be seen through a time series analysis.
Where each day of the mosquito season is analysed per user, and their completion of a report and reception of messages transformed into a binary variable. 


```{r Report Time Series, echo = TRUE}
contingency_table <- table(report_msg_wide$Msg_Received,report_msg_wide$Report)
contingency_table
chi_test_result <- chisq.test(contingency_table)
print(chi_test_result)

rm(contingency_table,chi_test_result)
```

Measuring how much the observed frequencies of the number of days with/without messages and reports deviate from the expected frequencies under the null hypothesis (no association between receiving messages and filling reports). The Pearson's Chi-squared test shows a clear in variation of days with/without messages when it comes to a report being filled by the participation. **p-value = 0.003997**


### Generalized Linear Model 
```{r Report time series GLM, echo = TRUE}
model <- glmer(Report ~ Msg_Received + (1 + Date|User_ID),
               data = report_msg_wide,
               family = binomial)

summary(model)
```


The logistic regression analysis revealed that receiving a message  increases the likelihood of a user filing a report, with statistical significance, suggesting a positive  correlation between message receipt and report filing behavior **(coefficient = 0.28091 , p = 0.000235)**


### Reporting intensity 
```{r Report time series poisson, echo = TRUE}
model <- glmer(total_reports ~ Msg_Received + (1 + Date|User_ID), 
               data = report_msg_wide, 
               family = poisson) 
summary(model)
```

Completing the analysis using Poisson regression to check if messaging helps with the intensity of messaging indicates that receiving a message is positively associated with the total number of reports filed **(coefficient = 0.22573, p = 8.97e-07)**, suggesting that message receipt  increases report filing frequency on a given date.


Based on  the three separate approaches **The alternative hypothesis, which posits that the true mean is not equal to zero, is supported by the data** showing that messaging has a positive impact on participant report filling.


### Variation between message type on report filing
```{r Report time series msg type, echo = TRUE}
report_msg_wide$Msg_Type <- relevel(report_msg_wide$Msg_Type, ref = "None")


model <- glmer(Report ~ Msg_Type + (1 + Date|User_ID), 
               data = report_msg_wide, 
               family = binomial(link = "logit"))
summary(model)
```

Both Prevention and Promotion messages seem to be more effective than Neutral messages in spurring users to fill reports.

### Importance of Message and Orientation Agreement
```{r Message and Orientation Agreement , echo = TRUE}
contingency_table <- table(report_msg_wide[report_msg_wide$Msg_Received == 1, ]$Orientation_Msg_Agreement,report_msg_wide[report_msg_wide$Msg_Received == 1, ]$Report)

chi_test_result <- chisq.test(contingency_table)
print(chi_test_result)
```
From the contingency table we see that whenever messages are sent, users are more likely to fill a report when there is an agreement between the message sent  and their regulatory orientation. Doing a chi test we see that the difference in the averages is significant with **p = 0.01918** 

Looking further into detail we compare between different regulatory orientations.

### Importance of Message Agreement with specific Orientation.
```{r Message value per specific Orientation , echo = TRUE}

model <- glmer(Report ~ Orientation_Msg_Agreement + (1 + Date|User_ID), 
               data = report_msg_wide[report_msg_wide$Reg_Orientation_Cat == "Prevention", ], 
               family = binomial(link = "logit"))
summary(model)


model <- glmer(Report ~ Orientation_Msg_Agreement + (1 + Date|User_ID), 
               data = report_msg_wide[report_msg_wide$Reg_Orientation_Cat == "Promotion", ], 
               family = binomial(link = "logit"))
summary(model)
```
Using Generalized Models after segmenting the data to include only those with either prevention or promotion orientation, we see that although message type agreement with the users regulatory focus has a positive impact in both cases, the effect is significant for those with prevention orientation **p = 0.02**.

